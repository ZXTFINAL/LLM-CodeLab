{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据格式化，看你的数据源格式,期望得到的格式如下\n",
    "\n",
    "如果你的格式是：\n",
    "{'content': 'xxxxxxx', 'summary': 'xxxxxxxxxxxxxxxxx}\n",
    "{'content': 'xxxxxxx', 'summary': 'xxxxxxxxxxxxxxxxx}\n",
    "下面的脚本可以帮你处理成：\n",
    "{\n",
    "    'conversations': [\n",
    "                {'role': 'user', 'content': 'xxxxxxx'},\n",
    "                {'role': 'assistant', 'content': 'xxxxxxxxxxxxxxxxx'}\n",
    "    ]\n",
    "}\n",
    "这个格式可以区分不同的角色，也可以加入系统信息，同时，也可以进行多轮会话训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def _mkdir(dir_name: Union[str, Path]):\n",
    "    dir_name = _resolve_path(dir_name)\n",
    "    if not dir_name.is_dir():\n",
    "        dir_name.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
    "    def _convert(in_file: Path, out_file: Path):\n",
    "        _mkdir(out_file.parent)\n",
    "        with open(in_file, encoding='utf-8') as fin:\n",
    "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
    "                for line in fin:\n",
    "                    dct = json.loads(line)\n",
    "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
    "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
    "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    data_dir = _resolve_path(data_dir)\n",
    "    save_dir = _resolve_path(save_dir)\n",
    "\n",
    "    train_file = data_dir / 'train.json'\n",
    "    if train_file.is_file():\n",
    "        out_file = save_dir / train_file.relative_to(data_dir)\n",
    "        _convert(train_file, out_file)\n",
    "\n",
    "    dev_file = data_dir / 'dev.json'\n",
    "    if dev_file.is_file():\n",
    "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
    "        _convert(dev_file, out_file)\n",
    "\n",
    "\n",
    "convert_adgen('data/ting', 'data/ting_fix')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lora开始训练！\n",
    "此处采用的是lora方式\n",
    "lora可调整的参数就是r, lora_alpha, lora_dropout\n",
    "分别是低维矩阵的秩（也就是降维矩阵的输出，升维矩阵的输入），lora和原网络的合并权重alpha，lora的dropout\n",
    "\n",
    "peft_config:\n",
    "  peft_type: LORA\n",
    "  task_type: CAUSAL_LM\n",
    "  r: 8\n",
    "  lora_alpha: 32\n",
    "  lora_dropout: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python3 utils/finetune_hf.py  data/ting_fix  llm_weights/chatglm3-6b  configs/lora.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
